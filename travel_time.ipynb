{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travel time estimation using tensor decomposition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "https://www.microsoft.com/en-us/research/publication/trajectory-data-mining-an-overview/ \n",
    "\n",
    "https://www.microsoft.com/en-us/research/wp-content/uploads/2015/09/TrajectoryDataMining-tist-yuzheng.pdf\n",
    "\n",
    "https://towardsdatascience.com/recommendation-system-matrix-factorization-d61978660b4b\n",
    "\n",
    "Formula to implement:\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}(S, R, U, T, F, G)=&\\frac{1}{2}\\left\\|\\mathcal{A}-S \\times_R R \\times_U U \\times_T T\\right\\|^2+\\frac{\\lambda_1}{2}\\|X-T G\\|^2 \\\\\n",
    "+&\\frac{\\lambda_2}{2}\\|Y-R F\\|^2+\\frac{\\lambda_3}{2}\\left(\\|S\\|^2+\\|R\\|^2+\\|U\\|^2+\\|T\\|^2+\\|F\\|^2+\\|G\\|^2\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "\\phi_{i j k}= & S \\times_R R_{i *} \\times_U U_{j *} \\times_T T_{k *} ; \\\\\n",
    "R_{i *} & \\leftarrow R_{i *}-\\eta \\lambda_3 R_{i *}-\\eta\\left(\\phi_{i j k}-\\mathcal{A}_{i j k}\\right) \\times S \\times_U U_{j *} \\times_T T_{k *} \\\\\n",
    "& -\\eta \\lambda_2\\left(R_{i *} \\times F-Y_{i *}\\right) \\times F ; \\\\\n",
    "U_{j *} \\leftarrow & U_{j *}-\\eta \\lambda_3 U_{j *}-\\eta\\left(\\phi_{i j k}-\\mathcal{A}_{i j k}\\right) \\times S \\times_R R_{i *} \\times_T T_{k *} \\\\\n",
    "T_{k *} \\leftarrow & T_{k *}-\\eta \\lambda_3 T_{k *}-\\eta\\left(\\phi_{i j k}-\\mathcal{A}_{i j k}\\right) \\times S \\times_R R_{i *} \\times_U U_{j *} \\\\\n",
    "& \\quad-\\eta \\lambda_1\\left(T_{k *} \\times G-X_{k *}\\right) \\times G ; \\\\\n",
    "S \\leftarrow & S-\\eta \\lambda_3 S-\\eta\\left(\\phi_{i j k}-\\mathcal{A}_{i j k}\\right) \\times R_{i *} \\otimes U_{j *} \\otimes T_{k *} \\\\\n",
    "G \\leftarrow & G-\\eta \\lambda_3 G-\\eta \\lambda_1\\left(T_{k *} \\times G-X_{k *}\\right) \\times T_{k *} \\\\\n",
    "F \\leftarrow & F-\\eta \\lambda_3 F-\\eta \\lambda_2\\left(R_{i *} \\times F-Y_{i *}\\right) \\times R_{i *}\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula explaination\n",
    "\n",
    "This formula describes the loss function for a tensor decomposition (factorization) method in order to estimate the three-dimensional tensor $\\mathcal{A}$. \n",
    "\n",
    "$\\mathcal{A}$ encodes the user-specific travel time in the following way: and entry $\\mathcal{A_{ijk}}$ of $\\mathcal{A}$ is the time that the $j$-th driver takes to travel in the $i$-th road segment in the $k$-th daily time slot. Therefore $\\mathcal{A}$ is essentially a three dimensional array. We can know certain entries of this tensor by tracking user's GPS signal, but a large amount of entries in this tensor are unknows, as users will only drive in certain roads at certain times, therefore we aim to estimate them. Intuitively, we could try to guess some of the missing entries based on existing ones by eyeballing correlations in the data: for example, if at a given time of the day the travel time for users is large in certain road segments, we expect that there is traffic there, and therefore we can estimate long travel times for other drivers, too.\n",
    "\n",
    "\n",
    "In order to do this 2 more matrices are introduced: $X$ and $Y$\n",
    "\n",
    "We need to estimate the tensor A by decomposing it into a product. The measure of the \"fitness\" of the decomposition is given by the sum of the square of the difference between the entries for which A is known and its decomposition, ie.e the Froenbius norm. From this, we compute the gradient of this loss function with respect each component of the matrices we decompose A into, and use this in a gradient descent algorithm. Each iteration computes the gradient and updates the matrices in such a way the loss is minimized."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_tensor(s,r,u,t):\n",
    "    ''' phi tensor, defined above.\n",
    "    it's the product of the tensor s with the matrices r,u,t\n",
    "    has the same dimensions of A'''\n",
    "    return np.einsum('ijk,ai,bj,ck->abc',s,r,u,t)\n",
    "def phi_ijk(s,r,u,t,a,b,c):\n",
    "    '''(i,j,k)th component of phi,\n",
    "    i.e. the contraction of s with r,u,t tensors'''\n",
    "    return np.einsum('ijk,i,j,k->',s,r[a,:],u[b,:],t[c,:])\n",
    "def phi_ijk_2(s,ri,uj,tk):\n",
    "    '''a possibly more optimized version\n",
    "    ri,uj,tk=r[i,:],u[j,:],t[k,:]'''\n",
    "    return np.einsum('ijk,i,j,k->',s,ri,uj,tk)\n",
    "def rut(r,u,t,a,b,c):\n",
    "    '''tensor product of i,j,k th components\n",
    "    of r,u,t'''\n",
    "    return np.einsum('i,j,k->ijk',r[a,:],u[b,:],t[c,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=np.ones(shape=(2,2))\n",
    "a2D = np.array([[1, 2], [3, 4]])\n",
    "sel=np.array([[1, 0], [1, 0]])\n",
    "np.einsum('ij,ij,ji->',t1,a2D,sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[1., 2.],\n",
       "         [3., 4.]]],\n",
       "\n",
       "\n",
       "       [[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[1., 2.],\n",
       "         [3., 4.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tensordot(t1,a2D,axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latent dimensions\n",
    "dU=5\n",
    "dR=7\n",
    "dT=3\n",
    "#\n",
    "dX=11 #aka p\n",
    "dY=13 #aka q\n",
    "#\n",
    "n=3 #road segments\n",
    "m= 9 #drivers\n",
    "l= 4#time slots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor initialization\n",
    "\n",
    "s=np.random.rand(dR,dU,dT)\n",
    "r=np.random.rand(n,dR)\n",
    "u=np.random.rand(m,dU)\n",
    "t=np.random.rand(2*l,dT)\n",
    "phi=np.einsum('ijk,ai,bj,ck->abc',s,r,u,t)#tensor contraction between s,r,u,t: should be a nxmx2l tensor\n",
    "f=np.random.rand(dR,dY)\n",
    "g=np.random.rand(dT,dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 9, 8)\n"
     ]
    }
   ],
   "source": [
    "## those tensors whould be computed from data, here I randomly initialize them\n",
    "\n",
    "a=np.random.randint(0,15,size=(n,m,2*l))\n",
    "x=np.random.randint(0,5,size=(2*l,dX))\n",
    "y=np.random.randint(0,4,size=(n,dY))\n",
    "\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 0, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 1, 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 0, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 1, 1, 1]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(a > 0, 1, 0)#select only entries where a is greater than 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7, 9, 5, 8, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=np.einsum('ai,bj,ck->aibjck',r,u,t)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.703700905514776"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,j,k=0,1,5\n",
    "phi[i][j][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t@g-x)[k,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78950115, 0.43060236, 0.01633793])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.T[:,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.91371357e+00, -2.98270532e+00, -2.74896665e+00,\n",
       "         8.04947745e-01, -1.28885761e+00, -4.19519264e-02,\n",
       "        -3.93418715e-01, -5.87644734e-01, -4.37893046e-01,\n",
       "        -1.21319615e+00, -2.63166116e+00],\n",
       "       [-1.58917048e+00, -1.62679932e+00, -1.49931576e+00,\n",
       "         4.39027093e-01, -7.02956700e-01, -2.28810285e-02,\n",
       "        -2.14574767e-01, -3.20507711e-01, -2.38831542e-01,\n",
       "        -6.61690133e-01, -1.43533609e+00],\n",
       "       [-6.02963625e-02, -6.17240772e-02, -5.68870914e-02,\n",
       "         1.66575814e-02, -2.66716078e-02, -8.68152788e-04,\n",
       "        -8.14140337e-03, -1.21607149e-02, -9.06175478e-03,\n",
       "        -2.51058703e-02, -5.44595724e-02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('a,b->ab',t.T[:,k],(t@g-x)[k,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.91371357e+00, -2.98270532e+00, -2.74896665e+00,\n",
       "         8.04947745e-01, -1.28885761e+00, -4.19519264e-02,\n",
       "        -3.93418715e-01, -5.87644734e-01, -4.37893046e-01,\n",
       "        -1.21319615e+00, -2.63166116e+00],\n",
       "       [-1.58917048e+00, -1.62679932e+00, -1.49931576e+00,\n",
       "         4.39027093e-01, -7.02956700e-01, -2.28810285e-02,\n",
       "        -2.14574767e-01, -3.20507711e-01, -2.38831542e-01,\n",
       "        -6.61690133e-01, -1.43533609e+00],\n",
       "       [-6.02963625e-02, -6.17240772e-02, -5.68870914e-02,\n",
       "         1.66575814e-02, -2.66716078e-02, -8.68152788e-04,\n",
       "        -8.14140337e-03, -1.21607149e-02, -9.06175478e-03,\n",
       "        -2.51058703e-02, -5.44595724e-02]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tensordot( t[k,:],t[k,:]@g-x[k,:],axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.496344530819598"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ijk,i,j,k->',s,r[i,:],u[j,:],t[k,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "print(rut(r,u,t,0,0,0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('abc,b,c->a',s,u[j],t[k]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.66454547,  1.13463229,  0.48652242,  1.22359074, -1.50237014,\n",
       "        1.34449524,  1.78321477])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[i,:]-(phi_ijk(s,r,u,t,i,j,k)-a[i,j,k])*np.einsum('abc,b,c->a',s,u[j],t[k])-(r[i]@f-y[i])@f.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (428390435.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [165], line 33\u001b[1;36m\u001b[0m\n\u001b[1;33m    gradf=\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def matrix_factorization(a,x,y,epsilon=0.001,steps=1000,eta=0.001,dR=10,dU=10,dT=10,lamb1=1,lamb2=1,lamb3=1):\n",
    "    '''\n",
    "    element-wise optimization algorithm\n",
    "    a: target tensor of shape n x m x l \n",
    "    x,y: context matrices\n",
    "    steps: max iterations\n",
    "    eta: learning rate\n",
    "    epsilon: treshold for early stop\n",
    "    dR,dU,dT: dimensions of latent spaces\n",
    "    '''\n",
    "    n,m,twol=a.shape\n",
    "    dG=x.shape[1]\n",
    "    dF=y.shape[1]\n",
    "    #initialize s,r,u,t,f,g\n",
    "    s=np.random.rand(dR,dU,dT)\n",
    "    r=np.random.rand(n,dR)\n",
    "    u=np.random.rand(m,dU)\n",
    "    t=np.random.rand(twol,dT)\n",
    "    f=np.random.rand(dR,dF)\n",
    "    g=np.random.rand(dT,dG)\n",
    "    for steps in range(steps):\n",
    "        if True :#loss_i-loss_i-1 > epsilon\n",
    "            for i in range(n):\n",
    "                for j in range(m):\n",
    "                    for k in range(twol):\n",
    "                        if a[i,j,k]>0:\n",
    "                            phiijk=phi_ijk(s,r,u,t,i,j,k)\n",
    "                            #compute all gradients\n",
    "                            gradr=lamb3* r[i,:]+(phi_ijk(s,r,u,t,i,j,k)-a[i,j,k])*np.einsum('abc,b,c->a',s,u[j],t[k])+lamb2*(r[i]@f-y[i])@f.T\n",
    "                            gradu=lamb3* u[j,:]+(phi_ijk(s,r,u,t,i,j,k)-a[i,j,k])*np.einsum('abc,a,c->b',s,r[i],t[k])\n",
    "                            gradt=lamb3* t[k,:]+(phi_ijk(s,r,u,t,i,j,k)-a[i,j,k])*np.einsum('abc,a,b->c',s,r[i],u[j])+lamb1*(t[k]@g-x[k])@g.T\n",
    "                            grads=lamb3*s+ (phi_ijk(s,r,u,t,i,j,k)-a[i,j,k])*rut(r,u,t,i,j,k)\n",
    "                            gradg=lamb3*g+lamb1*np.tensordot( t[k,:],t[k,:]@g-x[k,:],axes=0)\n",
    "                            gradf=lamb3*f+lamb2*np.tensordot( r[i,:],r[i,:]@f-y[i,:],axes=0)\n",
    "                            #update all parameters\n",
    "                            r[i]=r[i] -eta*gradr\n",
    "                            u[j]=u[j]- eta*gradu\n",
    "                            t[k]=t[k]- eta*gradt\n",
    "                            g=g-gradg*eta\n",
    "                            f=f-gradf*eta\n",
    "                            s=s-eta*grads\n",
    "        #for i,j,k for which a[ijk]=! 0\n",
    "            #compute gradient of \n",
    "    return s,r,u,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33a2e84c581f807a98512e14b5d3ba9d677e9d077bd64ce3b8213804b8999a19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
